{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8b2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7348a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directories for your two datasets\n",
    "DATASET_DIR_CRACK = Path(\"./datasets/crack_dataset\")\n",
    "DATASET_DIR_JOIN  = Path(\"./datasets/join_dataset\")\n",
    "\n",
    "# final merged dataset\n",
    "MERGED_DIR = Path(\"./datasets/merged_clipseg\")\n",
    "os.makedirs(MERGED_DIR / \"images\", exist_ok=True)\n",
    "os.makedirs(MERGED_DIR / \"masks\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb67ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_coco(base_dir):\n",
    "    coco_data = {\"images\": [], \"annotations\": [], \"categories\": []}\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        ann_path = base_dir / split / \"_annotations.coco.json\"\n",
    "        if ann_path.exists():\n",
    "            with open(ann_path) as f:\n",
    "                data = json.load(f)\n",
    "                # adjust image paths\n",
    "                for img in data[\"images\"]:\n",
    "                    img[\"split\"] = split\n",
    "                coco_data[\"images\"].extend(data[\"images\"])\n",
    "                coco_data[\"annotations\"].extend(data[\"annotations\"])\n",
    "                coco_data[\"categories\"].extend(data[\"categories\"])\n",
    "    return coco_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3399501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded Cracks: 5369 imgs, 8511 anns\n",
      "✅ Loaded Joins:  1022 imgs, 1424 anns\n"
     ]
    }
   ],
   "source": [
    "coco_crack = load_all_coco(DATASET_DIR_CRACK)\n",
    "coco_join  = load_all_coco(DATASET_DIR_JOIN)\n",
    "print(f\"✅ Loaded Cracks: {len(coco_crack['images'])} imgs, {len(coco_crack['annotations'])} anns\")\n",
    "print(f\"✅ Loaded Joins:  {len(coco_join['images'])} imgs, {len(coco_join['annotations'])} anns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1646c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(img_path, anns, save_path, is_crack):\n",
    "    img = Image.open(img_path)\n",
    "    mask = Image.new(\"L\", img.size, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    if is_crack:\n",
    "        # polygon segmentations\n",
    "        for ann in anns:\n",
    "            if \"segmentation\" in ann and len(ann[\"segmentation\"]) > 0:\n",
    "                poly = ann[\"segmentation\"][0]\n",
    "                xy = [(poly[i], poly[i+1]) for i in range(0, len(poly), 2)]\n",
    "                draw.polygon(xy, fill=255)\n",
    "    else:\n",
    "        # bbox → filled rectangle\n",
    "        for ann in anns:\n",
    "            if \"bbox\" in ann:\n",
    "                x, y, w, h = ann[\"bbox\"]\n",
    "                draw.rectangle([x, y, x+w, y+h], fill=255)\n",
    "    mask.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac7d774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing crack: 100%|██████████| 5369/5369 [02:00<00:00, 44.71it/s]\n",
      "Processing join: 100%|██████████| 1022/1022 [00:22<00:00, 45.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged dataset ready: 6391 total images\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "\n",
    "for dataset, coco_data, is_crack, prompt in [\n",
    "    (\"crack\", coco_crack, True, \"segment crack\"),\n",
    "    (\"join\",  coco_join,  False, \"segment taping area\")\n",
    "]:\n",
    "    for img in tqdm(coco_data[\"images\"], desc=f\"Processing {dataset}\"):\n",
    "        anns = [a for a in coco_data[\"annotations\"] if a[\"image_id\"] == img[\"id\"]]\n",
    "        src_img = (DATASET_DIR_CRACK if is_crack else DATASET_DIR_JOIN) / img[\"split\"] / img[\"file_name\"]\n",
    "        if not src_img.exists(): \n",
    "            continue\n",
    "        dst_img = MERGED_DIR / \"images\" / f\"{dataset}_{img['file_name']}\"\n",
    "        dst_mask = MERGED_DIR / \"masks\" / f\"{dataset}_{Path(img['file_name']).stem}.png\"\n",
    "        # copy image\n",
    "        Image.open(src_img).save(dst_img)\n",
    "        # make mask\n",
    "        make_mask(src_img, anns, dst_mask, is_crack)\n",
    "        metadata.append({\n",
    "            \"image\": str(dst_img.name),\n",
    "            \"mask\": str(dst_mask.name),\n",
    "            \"prompt\": prompt\n",
    "        })\n",
    "\n",
    "# save metadata\n",
    "with open(MERGED_DIR / \"metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"✅ Merged dataset ready: {len(metadata)} total images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "828974f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset fully split with images, masks, and JSON files ready.\n",
      "Train: 4473, Val: 1278, Test: 640\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths\n",
    "dataset_dir = r\"datasets\\merged_clipseg\"\n",
    "metadata_path = os.path.join(dataset_dir, \"metadata.json\")\n",
    "output_dir = os.path.join(dataset_dir, \"splits\")\n",
    "\n",
    "# Load metadata\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Shuffle dataset\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split ratios\n",
    "total = len(data)\n",
    "train_end = int(0.7 * total)\n",
    "val_end = int(0.9 * total)  # 70 + 20\n",
    "\n",
    "train_data = data[:train_end]\n",
    "val_data = data[train_end:val_end]\n",
    "test_data = data[val_end:]\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_data,\n",
    "    \"val\": val_data,\n",
    "    \"test\": test_data\n",
    "}\n",
    "\n",
    "# Create folders\n",
    "for split in splits.keys():\n",
    "    os.makedirs(os.path.join(output_dir, split, \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, split, \"masks\"), exist_ok=True)\n",
    "\n",
    "# Copy files and update JSON paths\n",
    "for split_name, split_items in splits.items():\n",
    "    split_json = []\n",
    "    for item in split_items:\n",
    "        # Source paths\n",
    "        img_src = os.path.join(dataset_dir, \"images\", item[\"image\"])\n",
    "        mask_src = os.path.join(dataset_dir, \"masks\", item[\"mask\"])\n",
    "\n",
    "        # Destination paths\n",
    "        img_dst = os.path.join(output_dir, split_name, \"images\", item[\"image\"])\n",
    "        mask_dst = os.path.join(output_dir, split_name, \"masks\", item[\"mask\"])\n",
    "\n",
    "        # Copy files\n",
    "        shutil.copy(img_src, img_dst)\n",
    "        shutil.copy(mask_src, mask_dst)\n",
    "\n",
    "        # Update paths in JSON\n",
    "        split_json.append({\n",
    "            \"image\": os.path.join(\"images\", item[\"image\"]),\n",
    "            \"mask\": os.path.join(\"masks\", item[\"mask\"]),\n",
    "            \"prompt\": item[\"prompt\"]\n",
    "        })\n",
    "\n",
    "    # Save split JSON\n",
    "    with open(os.path.join(output_dir, f\"{split_name}.json\"), \"w\") as f:\n",
    "        json.dump(split_json, f, indent=4)\n",
    "\n",
    "print(\"✅ Dataset fully split with images, masks, and JSON files ready.\")\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d5e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
